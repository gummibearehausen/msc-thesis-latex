\chapter{Learning Rules With Numerical and Categorical Attributes}
\label{cl:intro}

\section{Interesting Rules}

In this section we formally define what kind of rules we are interested in obtaining with the algorithm proposed in
this thesis. As briefly explained in the introduction, we focus on learning 

\section{Preprocessing}

In this section, we will present the preprocessing steps required by our proposed algorithm. It basically consists of
first building a graph with the knowlw building a joinable relations map for each of the four join patterns, according
to relations domain and range types as well as support threshold. Afterwards, we search the available categorical
properties for each numerical relation that will be used in the \graphname. At last we build the so called \graphname,
which belongs to the preprocessing step but will be discussed in the next Section s\ref{ch:lattice}.

\subsection{Relation Preprocessing}

In this step, we focus on creating for each of the four join patterns between two relations:

\begin{itemize}
 \item Argument 1 on Argument 1: e.g. \emph{hasIncome(\textbf{x},y)hasAge(\textbf{x},z)}
 \item Argument 1 on Argument 2: e.g. \emph{hasIncome(\textbf{x},y)isMarriedTo(z,\textbf{x})}
 \item Argument 2 on Argument 1: e.g. \emph{livesIn(y,\textbf{x})isLocatedIn(\textbf{x},z)}
 \item Argument 2 on Argument 2: e.g. \emph{livesIn(y,\textbf{x})wasBornIn(z,\textbf{x})}
\end{itemize}

\subsubsection{Exploiting Relation Range and Domain Types}

A knowledge base is expected to have an ontology defining the structure of the stored data (the types of entities and
their relationships). Additionally, every relation's range (type of \ord{1} argument) and domain (type of \ord{2}
argument) should be defined. These information can help us identify the allowed joining relations for each join pattern.

Assuming that the knowledge base has its type hierarchy described with the relation $rdfs:subClassOf$ and both argument
types from each of the relations declared with $rdfs:domain$ and $rdfs:range$ it's a really straightforward task.

For every possible pair of relations, we simply try to match the joining arguments from the 2 joining relations. We
check whether they are equal or if one can be subsumed by the other. If so, then theoretically the pair of relations
can be joined, or in other words, the type hierarchy allows them to be joined. The algorithm for performing such task is
shown in the pseudo-code bellow:

\begin{algorithm}[!h]
 \caption{Checks whether two relations are joinable for a given join pattern}
 \label{alg1}
 \SetKwFunction{subsumes}
 \KwIn{\textbf{Input:} Relation $r_i$, $r_j$, Argument $arg_i$, $arg_j$ \\}
 \KwOut{True if $arg_i$ from $r_i$ joins with $arg_j$ from $r_j$, False otherwise}
  \Switch{$arg_i$} {
      \Case{$1$}{
	$type_i \leftarrow r_i.domain$ \;
      }
      \Case{$2$}{
	$type_i \leftarrow r_i.range$ \;
      }
  }
  \Switch{$arg_j$} {
      \Case{$1$}{
	$type_j \leftarrow r_j.domain$ \;
      }
      \Case{$2$}{
	$type_j \leftarrow r_j.range$ \;
      }
  }
  \eIf{$type_i = type_j$ {\bf or} \FuncSty{subsumes(}$type_i$,$type_j$\FuncSty{)} {\bf or}
\FuncSty{subsumes(}$type_j$,$type_i$\FuncSty{)}}{
      \Return true\;
   }{
    \Return false\;
  }
\end{algorithm}

Nevertheless, it might be that in the knowledge base, the cardinality of such join might be zero or simply not exceed
the support threshold. Thus, it's worth to that beforehand, and that's what will be explained in the next section.

\subsubsection{Exploiting Support Monotonicity}

As seen in (???), support is the only monotonically decreasing measure in top-down ILP. So we know that by adding any
literals to the hypothesis, we can only get a smaller or equal support. Therefore, for each pair of joinable relations
in each of the join patterns, we can query the knowledge base and check whether they have enough supporting facts.

Thus, if any pair of relations doesn't reach the minimum support for a given join pattern, we know that any hypothesis
containing such join will therefore fail the support test as well, so we don't need to test such hypothesis in the core
ILP algorithm.

\begin{algorithm}[!h]
  \caption{Checks whether join support exceeds threshold}
  \label{alg2}
  \SetKwFunction{executeQuery}
  \KwIn{\textbf{Input:} Relation $r_i$, $r_j$, Argument $arg_i$, $arg_j$, Float $supportThreshold$ \\ }
  \KwOut{True if join support exceeds threshold, False otherwise}
    \Switch{$(arg_i,arg_j)$} {
      \Case{$(1,1)$}{
	$query \leftarrow$ \emph{``select count distinct $?x$ where \{ $?x$ <$r_i$> $?y$ . $?x$ <$r_j$> $?z$ \}''} \;
      }
      \Case{$(1,2)$}{
	$query \leftarrow$ \emph{``select count distinct $?x$ where \{ $?x$ <$r_i$> $?y$ . $?z$ <$r_j$> $?x$ \}''} \;
      }
      \Case{$(2,1)$}{
	$query \leftarrow$ \emph{``select count distinct $?x$ where \{ $?y$ <$r_i$> $?x$ . $?x$ <$r_j$> $?z$ \}''} \;
      }
      \Case{$(2,2)$}{
	$query \leftarrow$ \emph{``select count distinct $?x$ where \{ $?y$ <$r_i$> $?x$ . $?z$ <$r_j$> $?x$ \}''} \;
      }
    }
    $joinSupport \leftarrow$ executeQuery($query$)\;
     \eIf{$joinSupport \ge supportThreshold$} {
      \Return true\;
    }{
      \Return false\;
    }
\end{algorithm}


Applying \ref{alg1} and \ref{alg2} on all the possible join combinations and extracting the valid ones, we can build 4
maps joining maps, one for each join pattern. Each map has relations as keys and a set of joinable relations as value.
In the refinement step at the ILP algorithm, these maps will be queried in order to obtain the eligible literals to be
added.

\subsection{}

\section{\graphname}
\label{ch:lattice}
\input{./Chapters/correlation-lattice}

\section{Incorporating \graphname into Core ILP Algorithm}
