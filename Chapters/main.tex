\chapter{Learning Rules With Numerical and Categorical Attributes}
\label{cl:intro}

\section{Interesting Rules}

In this section we formally define what kind of rules we are interested in obtaining with the algorithm proposed in
this thesis. As briefly explained in the introduction, the objective learning with numerical attributes, focusing on searching ranges in the numerical domain that satisfy support and accuracy thresholds.

Trying to learn numerical ranges for a base-rule that already satisfies accuracy threshold is considered uninteresting, as the gain would be probably small

\section{Categorical Relation Definition}

In this section, we formally define a categorical relation as used in the \graphname. 

First of all, a candidate relation must be joined with root relation's \ord{1} argument (assuming that the numerical
attribute is in the \ord{2} argument). 

A candidate categorical relation $r(x,y)$, should be equivalent a non-injective function:

$r(x,y) \equiv f : X \rightarrow Y , \quad s.t. \, |Y|<|X| $ and $ |Y|>1 \newline $
$\nexists \, g : Y \rightarrow X , \quad s.t. \, f(g(x))=x , \quad \forall x \in X$

We can define subsets of $X_i \in X$, with which of them belonging to one category $y_i \in Y$:

$X_i \subset X \quad s.t. \, X_i = \{x \in X \,|\, f(x)=y_i ,\, y_i \in Y\} \newline $
$X = \bigcup_{i=1}^{n} X_i $ and $ X_i \cap X_j = \emptyset ,\quad \forall i,j \in [1,n] ,\, i \neq j$

We can also broaden this definition by composing functional relations to a categorical or multiple categorical
relations:

If we have:

$r_1(x,y) \equiv f_1 : X \rightarrow Y$ \newline
$r_2(y,z) \equiv f_2 : Y \rightarrow Z$ 

Where at least one of them is categorical, then $r'(x,z) \equiv f : X \rightarrow Z$, where $r'(x,z)=r_2(f_1(x),z)$ is also categorical


Numerical properties can also be turned into a categorical, by simply applying a bucketing function that maps a
numerical domain into a finite set of $k$ buckets:

$b: \mathbb{N} \rightarrow B$, where $B=\{1,2,\dots ,k \}$

So a numerical property:

$r(x,y) \equiv f : X \rightarrow \mathbb{N}$ 

combined with a bucketing function $b$, $r'(x,b(y))$ would be discretized and applicable in the \graphname.

(Then talk about non-categorical relations as categorical by considering its presence/absence)

Types are also covered by this definition. If we consider $r = rdf:type$ we see that $r$ which maps entities into
types satisfies the definition presented before.

\subsection{Absence or Presence of a Relation as Categories}

Another possibility is to define categories for presence or absence of relations. With this approach, one can also
include non-categorical relations into the \graphname and have insight about how the presence or absence of such
relation affects the distribution of root's numerical attribute.

As in this thesis we are under open world assumption and we don't consider negated literals in the hypothesis, we ignore
the absence and just include the presence of relations in the lattice.


%\subsection{Notation Used}
%
%As we will see in the next sections, in the \graphname all the relations are joined by a single variable $x$. So we will denote:
%
%$r(x,y)$ as $r$
%
%$r(x,C_i) or r(C)$ as $r_i$

\section{Preprocessing}

In this section, we will present the preprocessing steps required by our proposed algorithm. It basically consists of
first building a graph with the knowlw building a joinable relations map for each of the four join patterns, according
to relations domain and range types as well as support threshold. Afterwards, we search the available categorical
properties for each numerical relation that will be used in the \graphname. At last we build the so called \graphname,
which belongs to the preprocessing step but will be discussed in the next Section s\ref{ch:lattice}.

\subsection{Relation Preprocessing}

In this step, we focus on creating for each of the four join patterns between two relations:

\begin{itemize}
 \item Argument 1 on Argument 1: e.g. \emph{hasIncome(\textbf{x},y)hasAge(\textbf{x},z)}
 \item Argument 1 on Argument 2: e.g. \emph{hasIncome(\textbf{x},y)isMarriedTo(z,\textbf{x})}
 \item Argument 2 on Argument 1: e.g. \emph{livesIn(y,\textbf{x})isLocatedIn(\textbf{x},z)}
 \item Argument 2 on Argument 2: e.g. \emph{livesIn(y,\textbf{x})wasBornIn(z,\textbf{x})}
\end{itemize}

\subsubsection{Exploiting Relation Range and Domain Types}

A knowledge base is expected to have an ontology defining the structure of the stored data (the types of entities and
their relationships). Additionally, every relation's range (type of \ord{1} argument) and domain (type of \ord{2}
argument) should be defined. These information can help us identify the allowed joining relations for each join pattern.

Assuming that the knowledge base has its type hierarchy described with the relation $rdfs:subClassOf$ and both argument
types from each of the relations declared with $rdfs:domain$ and $rdfs:range$ it's a really straightforward task.

For every possible pair of relations, we simply try to match the joining arguments from the 2 joining relations. We
check whether they are equal or if one can be subsumed by the other. If so, then theoretically the pair of relations
can be joined, or in other words, the type hierarchy allows them to be joined. The algorithm for performing such task is
shown in the pseudo-code bellow:

\begin{algorithm}[!h]
 \caption{Checks whether two relations are joinable for a given join pattern}
 \label{alg1}
 \SetKwFunction{subsumes}
 \KwIn{\textbf{Input:} Relation $r_i$, $r_j$, Argument $arg_i$, $arg_j$ \\}
 \KwOut{True if $arg_i$ from $r_i$ joins with $arg_j$ from $r_j$, False otherwise}
  \Switch{$arg_i$} {
      \Case{$1$}{
	$type_i \leftarrow r_i.domain$ \;
      }
      \Case{$2$}{
	$type_i \leftarrow r_i.range$ \;
      }
  }
  \Switch{$arg_j$} {
      \Case{$1$}{
	$type_j \leftarrow r_j.domain$ \;
      }
      \Case{$2$}{
	$type_j \leftarrow r_j.range$ \;
      }
  }
  \eIf{$type_i = type_j$ {\bf or} \FuncSty{subsumes(}$type_i$,$type_j$\FuncSty{)} {\bf or}
\FuncSty{subsumes(}$type_j$,$type_i$\FuncSty{)}}{
      \Return true\;
   }{
    \Return false\;
  }
\end{algorithm}

Nevertheless, it might be that in the knowledge base, the cardinality of such join might be zero or simply not exceed
the support threshold. Thus, it's worth to that beforehand, and that's what will be explained in the next section.

\subsubsection{Exploiting Support Monotonicity}

As seen in (???), support is the only monotonically decreasing measure in top-down ILP. So we know that by adding any
literals to the hypothesis, we can only get a smaller or equal support. Therefore, for each pair of joinable relations
in each of the join patterns, we can query the knowledge base and check whether they have enough supporting facts.

Thus, if any pair of relations doesn't reach the minimum support for a given join pattern, we know that any hypothesis
containing such join will therefore fail the support test as well, so we don't need to test such hypothesis in the core
ILP algorithm.

\begin{algorithm}[!h]
  \caption{Checks whether join support exceeds threshold}
  \label{alg2}
  \SetKwFunction{executeQuery}
  \KwIn{\textbf{Input:} Relation $r_i$, $r_j$, Argument $arg_i$, $arg_j$, Float $supportThreshold$ \\ }
  \KwOut{True if join support exceeds threshold, False otherwise}
    \Switch{$(arg_i,arg_j)$} {
      \Case{$(1,1)$}{
	$query \leftarrow$ \emph{``select count distinct $?x$ where \{ $?x$ <$r_i$> $?y$ . $?x$ <$r_j$> $?z$ \}''} \;
      }
      \Case{$(1,2)$}{
	$query \leftarrow$ \emph{``select count distinct $?x$ where \{ $?x$ <$r_i$> $?y$ . $?z$ <$r_j$> $?x$ \}''} \;
      }
      \Case{$(2,1)$}{
	$query \leftarrow$ \emph{``select count distinct $?x$ where \{ $?y$ <$r_i$> $?x$ . $?x$ <$r_j$> $?z$ \}''} \;
      }
      \Case{$(2,2)$}{
	$query \leftarrow$ \emph{``select count distinct $?x$ where \{ $?y$ <$r_i$> $?x$ . $?z$ <$r_j$> $?x$ \}''} \;
      }
    }
    $joinSupport \leftarrow$ executeQuery($query$)\;
     \eIf{$joinSupport \ge supportThreshold$} {
      \Return true\;
    }{
      \Return false\;
    }
\end{algorithm}


Applying \ref{alg1} and \ref{alg2} on all the possible join combinations and extracting the valid ones, we can build 4
maps joining maps, one for each join pattern. Each map has relations as keys and a set of joinable relations as value.
In the refinement step at the ILP algorithm, these maps will be queried in order to obtain the eligible literals to be
added.

\subsection{}

\section{\graphname}
\label{ch:lattice}
\input{./Chapters/correlation-lattice}

\section{Incorporating \graphname into Core ILP Algorithm}
