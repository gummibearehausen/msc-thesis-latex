\chapter{Algorithmic Framework}
\label{ch:intro}

\section{Preprocessing}

In this section, we will present the preprocessing steps required by our proposed algorithm. It basically consists of building a joinable repations map for each of the four join patterns, according to relations domain and range types as well as support threshold. Afterwards, we search the available categorical properties for each numerical relation that will be used in the Influence Graphs. At last we describe an Influence Graph and the algorithm to build it.

\subsection{Relation Preprocessing}

In this step, we focus on creating for each of the four join patterns between two relations:

\begin{itemize}
 \item Argument 1 on Argument 1: e.g. hasIncome(\textbf{x},y)hasAge(\textbf{x},z)
 \item Argument 1 on Argument 2: e.g. hasIncome(\textbf{x},y)isMarriedTo(z,\textbf{x})
 \item Argument 2 on Argument 1: e.g. livesIn(y,\textbf{x})isLocatedIn(\textbf{x},z)
 \item Argument 2 on Argument 2: e.g. livesIn(y,\textbf{x})wasBornIn(z,\textbf{x})
\end{itemize}



\subsubsection{Exploiting Relation Range and Domain Types}

A knowledge base is expected to have an ontology defining the structure of the stored data (the types of entitties and their relationships). Additionally, every relation's range (type of 1st argument) and domain (type of 2nd argument) should be defined. These information can help us identify the allowed joining relations for each join pattern.

For every possible pair of relations, 

The algorithm is shown in the pseudo-code bellow:

\begin{algorithm}[5]
  %\caption{Checks valid join pairs for a given join patterns}
  %\begin{algorithmic}

  %\Function {checkIfJoinable}{$r_i$,$r_j$,$arg_i$,$arg_j$}
  %    \If{r_i.arg_i = r_j.arg_j \or subsumes(r_i.arg_i,r_j.arg_j) \or subsumes(r_j.arg_j,r_i.arg_i)}
	%  \Return true 
      %\Else
	%  \Return false
      %\EndIf
  %\EndFunction
  
  %\end{algorithmic}
%\SetAlgoLined
 \KwData{this text}
 \KwResult{how to write algorithm with \LaTeX2e }
 initialization\;
 \While{not at end of this document}{
  read current\;
  \eIf{understand}{
   go to next section\;
   current section becomes this one\;
   }{
   go back to the beginning of current section\;
  }
 }
 \caption{How to write algorithms}
\end{algorithm}

\subsubsection{Exploiting Support Monotonicity}

As seen in (???), support is the only monotonically decreasing measure in top-down ILP. So we know that by adding any literals to the hypothesis, we can only get a smaller or equal support. Therefore, for each pair of joinable realtions in each of the join patterns, we can query the knowledge base and check whether they reach the minimum support threshold.

Thus, if any pair of relations doesn't reach the minimum support for a given join pattern, we know that any hypothesis containing such join will therefore fail the support test as well, so we don't need to test such hypothesis in the core ILP algorithm.


\begin{algorithm}
  \caption{Checks valid join pairs for a given join patterns}
  %\begin{algorithmic}
 % \Function {checkJoinSupport}{r_i,r_j,arg_i,arg_j,supportThreshold}
 %     \If{r_i.arg_i = r_j.arg_j \or subsumes(r_i.arg_i,r_j.arg_j) \or subsumes(r_j.arg_j,r_i.arg_i)}
%	  \Return true 
 %     \Else
%	  \Return false
 %     \EndIf
  %\EndFunction
  
  %\end{algorithmic}
\end{algorithm}

The relation preprocessing will result in 4 maps, one for each join pattern. Each map will a relation as key and a set of joinable relations as value. The refinement step at the ILP algorithm, will then access this map when choosing a new literal to be added.


\subsection{Influence Graph}

\section{ILP Core Algorithm}


