\chapter{Algorithmic Framework}
\label{af:intro}

This thesis was implemented in Java, using the code from \citet{Teflioudi2011} as base for the core-ILP
algorithm, on which we added the changes in the refinement step mentioned at Section~\ref{sec:incorporation}. Also, we
change the knowledge base back-end to RDF3X, in order to improve the SPARQL queries performance.

\section{Knowledge Base Back-end}

For storing and retrieving RDF data we use RDF3X \citep{Neumann:2010:RES:1731351.1731354}. It has the advantage of being
specialized and optimized for RDF data, using a strong indexing approach with compressed B$^+$-Tree indices for each of
six permutations of \emph{subject (S)}, \emph{predicate (P)} and \emph{object (O)}:
\emph{SPO},\emph{SOP},\emph{OSP},\emph{OPS},\emph{PSO} and \emph{POS}.

All the facts are stored in a single triples table, with no schema, over which the indices are created. Moreover, one
important characteristic of the indices is that they feature count-aggregated variants in each of the one- and
two-dimensional projections.

The query processor explores the exhaustive indexation by relying mostly on merge-joins over the sorted index lists, and
building operator trees that preserve a convenient ordering which allows further merge-joins. When it is impossible,
RDF3X simply switches to hash-join.

RDF3X supports SPARQL queries, nevertheless, in the version 0.3.7 which was used in this thesis, many features of the
query language were not implement. For example, optional patterns are not supported, and sorting and filtering of
numerical attributes is not implemented, with numbers being dealt as strings. Therefore the expression $31>4$, for
example, will be evaluated as the comparison of strings $``31''>``4''$, which returns false instead of true.

As the evaluation of numerical expressions plays a key role in this thesis, we had to make changes to the original code
in order to support this feature.

The RDF3X process is accessed by the Java application via the JDBC interface.

\section{Preprocessing}

\subsection{Correlation Lattice Data Structure}

We structure the correlation lattice data in two main classes: \emph{CorrelationLattice} and
\emph{CorrelationLatticeNode}. 

\subsubsection{The CorrelationLatticeNode class}

Basically, in the \emph{CorrelationLattice} class, we store attributes related to the lattice as
a whole, such as the root property, root node, maximum number of levels, as well as attributes consistent through all
the lattice nodes, such as discretization boundaries, support and interestingness thresholds. Moreover, it maintains a
hash set with all the lattice nodes in order to avoid duplicate nodes.


\subsubsection{The CorrelationLatticeNode class}

In a \emph{CorrelationLatticeNode} we simply store the histogram data obtained with the discretization on root's
numerical attribute, a set of pointers to the child nodes

Every node essentially contains the following attributes:

\begin{itemize}
 \item Set of pointers to parent nodes
 \item Set of pointers to child nodes
 \item Set of pointers to constant nodes
 \item Histogram with facts distribution over root numerical property
\end{itemize}


\subsubsection{Building the Correlation Lattice}

For building the correlation lattice, we start with the root node, which has a numerical property as literal and no
constants assigned, e.g. \emph{hasIncome(x,y)}. We then query the  distribution of positive examples over the property
in the whole Knowledge Base.

\begin{center}
 \emph{SELECT COUNT ?y WHERE \{ ?x <hasIncome> ?y \} GROUP BY (?y)}
\end{center}

It's also necessary to specify the bucketing technique and the number of buckets in order to extract the histogram from the obtained query results. These buckets are used to build the histograms of all nodes in the graph.

Afterwards, we select the the categorical properties that will be used in the lattice. For each of the selected properties, we join them with the root numerical property (for simplicity we'll assume all the categorical properties are joined with both \ord{1} arguments) and we query the distribution again. In the first level, it's necessary to extract a histogram for each of the categorical constants in the selected properties. Therefore, it's a good strategy to group the results also by these categorical constants so If we select \emph{hasEducation} for example, we would then fire the following SPARQL query:

\begin{center}
 \emph{SELECT COUNT ?z ?y WHERE \{ ?x <hasIncome> ?y . ?x <hasEducation> ?z \} GROUP BY (?z,?y)}
\end{center}

With such query, we can extract a histogram for the node \emph{hasIncome(x,y)hasEducation(x,z)} and its correspondent
constants. 

For the further levels, we simply add a pattern correspondent to each literal in the node. 


\subsubsection{Searching Rules in Correlation Lattice}
\label{sec:searchRulesInCL}

In the lattice itself, it's possible to extract valuable rules. Given its characteristic of all the relations being
joined on the same root argument, those rules represent how different categories are related along root's numberical
constants.

For every non-root node in the correlation lattice, any of its parents can be seen as rule's body and the difference
literal as head. Below, we show an example using the notation defined at~\ref{sec:notation}:

For the node $r a_1 b_1 c_1$ with parents $r a_1 b_1$, $r a_1 c_1$ and $r b_1 c_1$, we can extract and easily evaluate three rules:

\begin{align*}
Rule_1: \quad &a_1\text{ :- }b_1,c_1,r \\ 
&supp(Rule_1) = h(r a_1 b_1 c_1) \\
&acc(Rule_1) = \frac{h(r a_1 b_1 c_1)}{h(r b_1 c_1)} \\ \\
Rule_2: \quad &b_1\text{ :- }a_1,c_1,r \\
 &supp(Rule_2) = h(r a_1 b_1 c_1) \\
 &acc(Rule_2) = \frac{h_i(r a_1 b_1 c_1)}{h(r a_1 c_1)} \\ \\
Rule_3: \quad &c_1\text{ :- }a_1,b_1,r \\
 &supp(Rule_3) = h(r a_1 b_1 c_1) \\
 &acc(Rule_3) = \frac{h(r a_1 b_1 c_1)}{h(r a_1 b_1)} 
\end{align*}

Therefore, in order to search for rules in the correlation lattice, we can simply perform a breadth-first traversal in
the lattice, and do such evaluation in each node. 

Subsequently we can analyze the frequency and confidence distributions and determine whether any of the rules are
interesting, using any of the techniques such as \citet{Brin99miningoptimized}, discussed
in~\ref{sec:rw-miningOptimizedRules}, in order to search for optimal intervals.


% Substitution for constants only in categorical relations, query by support
% When categorical joined to numerical property (without range) existent in \graphname query graph for constants
% 



